{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFA(nn.Module):\n",
    "    def __init__(self, input_channel, input_dim):\n",
    "        super(MFA, self).__init__()\n",
    "        \n",
    "        self.width = input_channel * input_dim\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool3d((None, None,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer = nn.Linear(self.width, self.width)\n",
    "    \n",
    "        self.flatten_tdnn = nn.Flatten(1,2)\n",
    "        \n",
    "        #TDNN with Conv1d\n",
    "        self.cnn = nn.Conv1d(self.width, input_channel, kernel_size=1)\n",
    "        self.relu = nn.ReLU()       \n",
    "        self.bn = nn.BatchNorm1d(input_channel)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        x = self.gap(x)\n",
    "        \n",
    "        x = x.squeeze(-1)\n",
    "        b,c,d = x.size()\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.layer(x)\n",
    "        \n",
    "        x = x.reshape(-1, c, d)\n",
    "        x = x.unsqueeze(-1)*x_\n",
    "        \n",
    "        x = self.flatten_tdnn(x)\n",
    "        \n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        #print(x.shape)\n",
    "        x = x.unsqueeze(2)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MFA(\n",
       "  (gap): AdaptiveAvgPool3d(output_size=(None, None, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "  (flatten_tdnn): Flatten(start_dim=1, end_dim=2)\n",
       "  (cnn): Conv1d(640, 8, kernel_size=(1,), stride=(1,))\n",
       "  (relu): ReLU()\n",
       "  (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfa = MFA(8, 80)\n",
    "mfa.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(1, 8, 80, 200)\n",
    "output = mfa(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DpMsModule(nn.Module):\n",
    "    def __init__(self, scale, channel_output, input_dim):\n",
    "        super(DpMsModule, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(1, channel_output, kernel_size=3, padding=(1,1))\n",
    "        self.cnn2 = nn.Conv2d(channel_output, channel_output, kernel_size=3, padding=(1,1))\n",
    "        self.width = channel_output//scale\n",
    "        self.scale = scale\n",
    "\n",
    "        self.mfa1 = MFA(self.width, input_dim)\n",
    "        self.mfa2 = MFA(self.width, input_dim)\n",
    "        self.mfa3 = MFA(self.width, input_dim)\n",
    "        self.mfa4 = MFA(self.width, input_dim)\n",
    "\n",
    "        self.cnn3_1 = nn.Conv2d(self.width, self.width, kernel_size=3, padding='same')\n",
    "        self.cnn3_2 = nn.Conv2d(self.width, self.width, kernel_size=3, padding='same')\n",
    "        self.cnn3_3 = nn.Conv2d(self.width, self.width, kernel_size=3, padding='same')\n",
    "\n",
    "        self.flatten = nn.Flatten(1,2)\n",
    "        \n",
    "        self.cnn4 = nn.Conv1d(channel_output, channel_output, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x1, x2, x3, x4 = torch.split(x, self.width, dim=1)\n",
    "\n",
    "        x1 = self.mfa1(x1)\n",
    "        x2 = self.cnn3_1(x2)\n",
    "        x2_ = x2\n",
    "        x2 = self.mfa2(x1*x2)\n",
    "        \n",
    "        x3 = self.cnn3_2(x2_+x3)\n",
    "        x3_ = x3\n",
    "        x3 = self.mfa3(x2*x3)\n",
    "        \n",
    "        x4 = self.cnn3_3(x3_+x4)\n",
    "        x4 = self.mfa4(x3*x4)\n",
    "\n",
    "\n",
    "        y = torch.cat((x1,x2,x3,x4), 1)\n",
    "        print(y.size())\n",
    "        y = self.flatten(y)\n",
    "        print(y.size())\n",
    "        y_ = y\n",
    "        y= self.cnn4(y)\n",
    "        y= y+y_\n",
    "\n",
    "        #batch, c, d, l = x1.size()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(1, 1,80,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DpMsModule(\n",
       "  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (mfa1): MFA(\n",
       "    (gap): AdaptiveAvgPool3d(output_size=(None, None, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (flatten_tdnn): Flatten(start_dim=1, end_dim=2)\n",
       "    (cnn): Conv1d(640, 8, kernel_size=(1,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (mfa2): MFA(\n",
       "    (gap): AdaptiveAvgPool3d(output_size=(None, None, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (flatten_tdnn): Flatten(start_dim=1, end_dim=2)\n",
       "    (cnn): Conv1d(640, 8, kernel_size=(1,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (mfa3): MFA(\n",
       "    (gap): AdaptiveAvgPool3d(output_size=(None, None, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (flatten_tdnn): Flatten(start_dim=1, end_dim=2)\n",
       "    (cnn): Conv1d(640, 8, kernel_size=(1,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (mfa4): MFA(\n",
       "    (gap): AdaptiveAvgPool3d(output_size=(None, None, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (flatten_tdnn): Flatten(start_dim=1, end_dim=2)\n",
       "    (cnn): Conv1d(640, 8, kernel_size=(1,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn3_1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (cnn3_2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (cnn3_3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=2)\n",
       "  (cnn4): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = DpMsModule(4,32, 80)\n",
    "check.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1, 200])\n",
      "torch.Size([1, 8, 1, 200])\n",
      "torch.Size([1, 8, 1, 200])\n",
      "torch.Size([1, 8, 1, 200])\n",
      "torch.Size([1, 32, 1, 200])\n",
      "torch.Size([1, 32, 200])\n"
     ]
    }
   ],
   "source": [
    "output = check(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 76])\n",
      "torch.Size([1, 8, 76, 196])\n",
      "torch.Size([1, 8, 76, 196])\n",
      "torch.Size([1, 608, 196])\n",
      "torch.Size([1, 608, 196])\n"
     ]
    }
   ],
   "source": [
    "check = mfa(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = nn.AdaptiveAvgPool3d((None, None,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 76, 1])\n",
      "torch.Size([1, 8, 76])\n"
     ]
    }
   ],
   "source": [
    "print(test3.shape)\n",
    "test3 = test3.squeeze(-1)\n",
    "print(test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layer(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 608])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = nn.Linear(608, 608)\n",
    "output = layer2(output)\n",
    "output = output.reshape(-1,8, 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 76])\n",
      "torch.Size([1, 8, 76, 196])\n",
      "torch.Size([1, 8, 76, 196])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())\n",
    "print(output_.size())\n",
    "final = output.unsqueeze(-1)*output_\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channel,\n",
    "        scaled_channel=128\n",
    "    ):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(input_channel, scaled_channel, kernel_size=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(scaled_channel,input_channel, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input\n",
    "    ):\n",
    "        print(input.shape)\n",
    "        output = self.block(input)\n",
    "        print(output.shape)\n",
    "        return output*input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(1, 80,150)\n",
    "check = SEBlock(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 150])\n",
      "torch.Size([1, 80, 1])\n"
     ]
    }
   ],
   "source": [
    "output = check(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ECPA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f2458aa68e1a6fb8fbdffd5d9dc36f76c36a9c723ad098c121392416287bb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
